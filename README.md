### 1. Data Cleaning and Preprocessing.ipynb
**Description**: This notebook covers essential techniques for data cleaning and preprocessing, which are crucial steps in any data analysis or machine learning project. It includes methods for handling missing data, encoding categorical variables, and scaling features.
 
**Contents**:
- **Handling Missing Data**: Techniques such as imputation and removal of missing values.
- **Encoding Categorical Variables**: Methods like one-hot encoding and label encoding.
- **Feature Scaling**: Scaling techniques including standardization and normalization.

### 2. fit, transform, fit_transform.ipynb
**Description**: This notebook explains the differences and usage of the `fit`, `transform`, and `fit_transform` methods in scikit-learn, a popular machine learning library in Python. It provides practical examples to demonstrate their applications.

**Contents**:
- **fit()**: Explanation of fitting a model to data.
- **transform()**: How to apply the learned parameters to transform data.
- **fit_transform()**: Combining the fitting and transforming steps in one method.

### 3. Hierarchical Clustering Agglomerative.ipynb
**Description**: This notebook demonstrates hierarchical clustering, specifically agglomerative clustering. It provides insights into how hierarchical clustering works and its applications in finding patterns in data.

**Contents**:
- **Agglomerative Clustering**: Explanation and implementation of agglomerative clustering.
- **Dendrograms**: Visual representation of hierarchical clustering.
- **Distance Metrics**: Different methods to compute the distance between clusters.

### 4. PCA using sklearn.ipynb
**Description**: This notebook covers Principal Component Analysis (PCA) using the scikit-learn library. PCA is a dimensionality reduction technique used to reduce the number of features in a dataset while retaining as much information as possible.

**Contents**:
- **Principal Component Analysis**: Introduction and theory behind PCA.
- **Implementation in sklearn**: Step-by-step guide to perform PCA using scikit-learn.
- **Visualization**: Visualizing the results of PCA.

### 5. Performance-Scoring-Confusion Metrics.ipynb
**Description**: This notebook focuses on evaluating the performance of classification models using various scoring metrics, with a particular emphasis on confusion metrics.

**Contents**:
- **Confusion Matrix**: Explanation and construction of a confusion matrix.
- **Performance Metrics**: Calculation of accuracy, precision, recall, and F1-score.
- **ROC Curve and AUC**: Plotting and interpreting ROC curves and calculating the area under the curve.

### 6. Principle Component Analysis from Scratch.ipynb
**Description**: This notebook provides a detailed explanation and implementation of Principal Component Analysis (PCA) from scratch, without using any libraries.

**Contents**:
- **Theory of PCA**: Mathematical foundation of PCA.
- **Implementation**: Step-by-step implementation of PCA using numpy.
- **Comparison with sklearn**: Comparing the custom implementation with scikit-learnâ€™s PCA.

### 7. Resampling.ipynb
**Description**: This notebook covers various resampling techniques used to handle imbalanced datasets, which is a common issue in machine learning.

**Contents**:
- **Under-sampling**: Reducing the number of majority class samples.
- **Over-sampling**: Increasing the number of minority class samples.
- **SMOTE**: Synthetic Minority Over-sampling Technique for generating synthetic samples.
